{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fc49f33-4105-45ee-b0d3-266a83a80fdb",
   "metadata": {},
   "source": [
    "# Indian Takeaway Orders Dataset - Analysis using PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7d1ce0d9-39c2-46af-9d26-027864392f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_timestamp, col, sum\n",
    "\n",
    "spark = SparkSession.builder.appName(\"MyApp\").getOrCreate()\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6a7e00-aa72-4467-9feb-8bf0201943d6",
   "metadata": {},
   "source": [
    "## Load CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43efd61d-e8a3-467a-a598-7a86299aba6a",
   "metadata": {},
   "source": [
    "#### Restaurant 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ff62f76-1cff-40d5-8796-5be1c4ce66e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+-------------------+--------+-------------+--------------+\n",
      "|Order Number|      Order Date|          Item Name|Quantity|Product Price|Total products|\n",
      "+------------+----------------+-------------------+--------+-------------+--------------+\n",
      "|       16118|03/08/2019 20:25|      Plain Papadum|       2|          0.8|             6|\n",
      "|       16118|03/08/2019 20:25|   King Prawn Balti|       1|        12.95|             6|\n",
      "|       16118|03/08/2019 20:25|        Garlic Naan|       1|         2.95|             6|\n",
      "|       16118|03/08/2019 20:25|      Mushroom Rice|       1|         3.95|             6|\n",
      "|       16118|03/08/2019 20:25|Paneer Tikka Masala|       1|         8.95|             6|\n",
      "+------------+----------------+-------------------+--------+-------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load orders file\n",
    "r1_orders_df = spark.read.csv(\"restaurant-1-orders.csv\", header = True, inferSchema = True)\n",
    "r1_orders_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3280f493-d28a-4b50-8919-e701fb93217a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+\n",
      "|    Item Name|Product Price|\n",
      "+-------------+-------------+\n",
      "|   Mint Sauce|          0.5|\n",
      "|  Lime Pickle|          0.5|\n",
      "|Mango Chutney|          0.5|\n",
      "|    Red Sauce|          0.5|\n",
      "|Onion Chutney|          0.5|\n",
      "+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load products price file\n",
    "r1_prices_df = spark.read.csv(\"restaurant-1-products-price.csv\", header = True, inferSchema = True)\n",
    "r1_prices_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e7cb3e-7b43-49f3-8365-8637cc984d44",
   "metadata": {},
   "source": [
    "#### Restaurant 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f28c7901-b562-4fe6-8851-22ff6fa1bcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+--------------------+--------+-------------+--------------+\n",
      "|Order ID|      Order Date|           Item Name|Quantity|Product Price|Total products|\n",
      "+--------+----------------+--------------------+--------+-------------+--------------+\n",
      "|   25583|03/08/2019 21:58|Tandoori Mixed Grill|       1|        11.95|            12|\n",
      "|   25583|03/08/2019 21:58|        Madras Sauce|       1|         3.95|            12|\n",
      "|   25583|03/08/2019 21:58|       Mushroom Rice|       2|         3.95|            12|\n",
      "|   25583|03/08/2019 21:58|         Garlic Naan|       1|         2.95|            12|\n",
      "|   25583|03/08/2019 21:58|             Paratha|       1|         2.95|            12|\n",
      "+--------+----------------+--------------------+--------+-------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load orders file\n",
    "r2_orders_df = spark.read.csv(\"restaurant-2-orders.csv\", header = True, inferSchema = True)\n",
    "r2_orders_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72b5f310-4a06-4c8f-b5e7-b62ccca21499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+\n",
      "|    Item Name|Product Price|\n",
      "+-------------+-------------+\n",
      "|Onion Chutney|          0.5|\n",
      "|   Mint Sauce|          0.5|\n",
      "|Mango Chutney|          0.5|\n",
      "|    Red Sauce|          0.5|\n",
      "|  Lime Pickle|          0.5|\n",
      "+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load products price file\n",
    "r2_prices_df = spark.read.csv(\"restaurant-2-products-price.csv\", header = True, inferSchema = True)\n",
    "r2_prices_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e9e672-c07f-4ca1-8153-9fd58ebb111e",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943712e3-0221-49dd-aa5b-5aadfc1a72db",
   "metadata": {},
   "source": [
    "### Check Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0922e29-a848-413a-9a29-a16bf400d3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant 1 Orders Schema:\n",
      "root\n",
      " |-- Order Number: integer (nullable = true)\n",
      " |-- Order Date: string (nullable = true)\n",
      " |-- Item Name: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- Product Price: double (nullable = true)\n",
      " |-- Total products: integer (nullable = true)\n",
      "\n",
      "Restaurant 2 Orders Schema:\n",
      "root\n",
      " |-- Order ID: integer (nullable = true)\n",
      " |-- Order Date: string (nullable = true)\n",
      " |-- Item Name: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- Product Price: double (nullable = true)\n",
      " |-- Total products: integer (nullable = true)\n",
      "\n",
      "Restaurant 1 Prices Schema:\n",
      "root\n",
      " |-- Item Name: string (nullable = true)\n",
      " |-- Product Price: double (nullable = true)\n",
      "\n",
      "Restaurant 2 Prices Schema:\n",
      "root\n",
      " |-- Item Name: string (nullable = true)\n",
      " |-- Product Price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Restaurant 1 Orders Schema:\")\n",
    "r1_orders_df.printSchema()\n",
    "print(\"Restaurant 2 Orders Schema:\")\n",
    "r2_orders_df.printSchema()\n",
    "print(\"Restaurant 1 Prices Schema:\")\n",
    "r1_prices_df.printSchema()\n",
    "print(\"Restaurant 2 Prices Schema:\")\n",
    "r2_prices_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcc9edd-cbe3-47e4-84bf-0a5a61b0915e",
   "metadata": {},
   "source": [
    "### Number of Total and Unique Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c941fa3b-633b-4d48-bb4f-8a2d48cd214d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant 1 - Total rows: 74818\n",
      "Restaurant 1 - Unique orders: 13397\n",
      "Restaurant 2 - Total rows: 119183\n",
      "Restaurant 2 - Unique orders: 19658\n"
     ]
    }
   ],
   "source": [
    "print(\"Restaurant 1 - Total rows:\", r1_orders_df.count())\n",
    "print(\"Restaurant 1 - Unique orders:\", r1_orders_df.select(\"Order Number\").distinct().count())\n",
    "\n",
    "print(\"Restaurant 2 - Total rows:\", r2_orders_df.count())\n",
    "print(\"Restaurant 2 - Unique orders:\", r2_orders_df.select(\"Order ID\").distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425717ad-f253-400f-8b72-da9241f6d2a2",
   "metadata": {},
   "source": [
    "### Summary Stats of Quantities and Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26c6da3f-2cb8-41a5-92e2-fdd505056fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant 1:\n",
      "+-------+------------------+-----------------+\n",
      "|summary|          Quantity|    Product Price|\n",
      "+-------+------------------+-----------------+\n",
      "|  count|             74818|            74818|\n",
      "|   mean|  1.24356438290251|5.286491886982787|\n",
      "| stddev|0.7982073410496792|  3.3382213559897|\n",
      "|    min|                 1|              0.5|\n",
      "|    max|                51|            17.95|\n",
      "+-------+------------------+-----------------+\n",
      "\n",
      "Restaurant 2:\n",
      "+-------+------------------+------------------+\n",
      "|summary|          Quantity|     Product Price|\n",
      "+-------+------------------+------------------+\n",
      "|  count|            119183|            119183|\n",
      "|   mean|1.2488693857345428| 5.108173145502638|\n",
      "| stddev|0.7022026750515845|3.2077047387844217|\n",
      "|    min|                 1|               0.5|\n",
      "|    max|                20|             17.95|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Restaurant 1:\")\n",
    "r1_orders_df.describe([\"Quantity\", \"Product Price\"]).show()\n",
    "print(\"Restaurant 2:\")\n",
    "r2_orders_df.describe([\"Quantity\", \"Product Price\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcfd481-b75b-4ee1-bcdc-34bcd1c28337",
   "metadata": {},
   "source": [
    "### Top Selling Items by Quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6fa8fd0-7b36-4519-9271-5d4ae8776659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant 1:\n",
      "+--------------------+--------------+\n",
      "|           Item Name|Total_Quantity|\n",
      "+--------------------+--------------+\n",
      "|       Plain Papadum|         10648|\n",
      "|          Pilau Rice|          6367|\n",
      "|          Plain Naan|          4983|\n",
      "|         Garlic Naan|          3318|\n",
      "|          Plain Rice|          2964|\n",
      "|        Onion Bhajee|          2749|\n",
      "|       Mango Chutney|          2504|\n",
      "|Chicken Tikka Masala|          2473|\n",
      "|             Chapati|          1935|\n",
      "|          Mint Sauce|          1840|\n",
      "+--------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Register the DataFrame as a SQL temporary view\n",
    "r1_orders_df.createOrReplaceTempView(\"r1_orders\")\n",
    "\n",
    "# SQL query\n",
    "top_items_r1 = spark.sql(\"\"\"\n",
    "    SELECT `Item Name`, SUM(Quantity) AS Total_Quantity\n",
    "    FROM r1_orders\n",
    "    GROUP BY `Item Name`\n",
    "    ORDER BY Total_Quantity DESC\n",
    "    LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "print(\"Restaurant 1:\")\n",
    "top_items_r1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5361d97d-8866-47b3-9a6e-4b4f6769654b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant 2:\n",
      "+--------------------+--------------+\n",
      "|           Item Name|Total_Quantity|\n",
      "+--------------------+--------------+\n",
      "|       Plain Papadum|         18056|\n",
      "|          Pilau Rice|         11754|\n",
      "|                Naan|          8730|\n",
      "|         Garlic Naan|          4809|\n",
      "|         Bombay Aloo|          4336|\n",
      "|       Mango Chutney|          4124|\n",
      "|Chicken Tikka Masala|          3970|\n",
      "|         Onion Bhaji|          3965|\n",
      "|          Plain Rice|          3532|\n",
      "|       Mushroom Rice|          3424|\n",
      "+--------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Register the DataFrame as a SQL temporary view\n",
    "r2_orders_df.createOrReplaceTempView(\"r2_orders\")\n",
    "\n",
    "# SQL query:\n",
    "top_items_r2 = spark.sql(\"\"\"\n",
    "    SELECT `Item Name`, SUM(Quantity) AS Total_Quantity\n",
    "    FROM r2_orders\n",
    "    GROUP BY `Item Name`\n",
    "    ORDER BY Total_Quantity DESC\n",
    "    LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "print(\"Restaurant 2:\")\n",
    "top_items_r2.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a174ec2e-d21d-4989-a8ff-3f323dc8981c",
   "metadata": {},
   "source": [
    "### Total Revenue per Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c59448f-12ba-48c0-8e53-ce8f73727738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant 1:\n",
      "+------------+------------------+\n",
      "|Order Number|           Revenue|\n",
      "+------------+------------------+\n",
      "|        6769|            1242.0|\n",
      "|        6768|            685.25|\n",
      "|       15840| 660.4499999999999|\n",
      "|        9412| 581.9999999999999|\n",
      "|        9411| 460.7499999999997|\n",
      "|        9374|432.04999999999995|\n",
      "|        9413|289.64999999999986|\n",
      "|        3976|268.49999999999994|\n",
      "|        9804|231.89999999999995|\n",
      "|        9414|224.84999999999988|\n",
      "+------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rev_per_order_r1 = spark.sql(\"\"\"\n",
    "    SELECT `Order Number`, SUM(Quantity * `Product Price`) AS Revenue\n",
    "    FROM r1_orders\n",
    "    GROUP BY `Order Number`\n",
    "    ORDER BY Revenue DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"Restaurant 1:\")\n",
    "rev_per_order_r1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62732222-1473-48a2-9895-73e0ae6007c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant 2:\n",
      "+--------+------------------+\n",
      "|Order ID|           Revenue|\n",
      "+--------+------------------+\n",
      "|    7952|             283.3|\n",
      "|   13246|234.50000000000006|\n",
      "|   14224|193.45000000000005|\n",
      "|   19569|183.65000000000003|\n",
      "|   22328|182.34999999999997|\n",
      "|   24856|175.95000000000002|\n",
      "|   21984|171.04999999999998|\n",
      "|    5170|167.60000000000002|\n",
      "|   24855|             167.0|\n",
      "|   17228|166.60000000000002|\n",
      "+--------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rev_per_order_r2 = spark.sql(\"\"\"\n",
    "    SELECT `Order ID`, SUM(Quantity * `Product Price`) AS Revenue\n",
    "    FROM r2_orders\n",
    "    GROUP BY `Order ID`\n",
    "    ORDER BY Revenue DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"Restaurant 2:\")\n",
    "rev_per_order_r2.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ddc6f1-0879-4ead-85c9-adc5be4bb9f4",
   "metadata": {},
   "source": [
    "(Change either Order ID or Order Number later)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c583e4-2ac8-4841-9534-befdafdbfdc3",
   "metadata": {},
   "source": [
    "### First and Last Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c81227c5-7f36-41d5-9c06-be279b900316",
   "metadata": {},
   "outputs": [],
   "source": [
    "#r1_orders_df.select(\n",
    "  #  min(\"Order Date\").alias(\"First_Order\"),\n",
    " #   max(\"Order Date\").alias(\"Last_Order\")\n",
    "#).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48732dd-a6e3-45cc-84b8-c76ae68e5a48",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e089fe-ed40-4bc2-8d07-d97975f1545b",
   "metadata": {},
   "source": [
    "### Column Names & Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa413ec-dfff-42ef-902a-a58c502cb85c",
   "metadata": {},
   "source": [
    "#### Convert Order Date to Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c42f90cb-4e60-45b6-ac69-43b10e07bd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant 1: TimestampType(), Restaurant 2: TimestampType()\n"
     ]
    }
   ],
   "source": [
    "# Import to_timestamp\n",
    "r1_orders_df = r1_orders_df.withColumn(\"Order Date\", to_timestamp(\"Order Date\", \"dd/MM/yyyy HH:mm\"))\n",
    "r2_orders_df = r2_orders_df.withColumn(\"Order Date\", to_timestamp(\"Order Date\", \"dd/MM/yyyy HH:mm\"))\n",
    "\n",
    "# Check\n",
    "print(f\"Restaurant 1: {r1_orders_df.schema['Order Date'].dataType}, Restaurant 2: {r2_orders_df.schema['Order Date'].dataType}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68158e29-65b6-421d-a155-039bed653a2f",
   "metadata": {},
   "source": [
    "#### Rename `Order Number` to `Order ID` for Restaurant 1\n",
    "(Both tables with the same column name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "577d0f5a-41f7-495c-b751-dc109ac628cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Order ID|\n",
      "+--------+\n",
      "|   16118|\n",
      "+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r1_orders_df = r1_orders_df.withColumnRenamed(\"Order Number\", \"Order ID\")\n",
    "r1_orders_df.select(\"Order ID\").show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bf2af8-7570-470e-91b0-57dc76afb7bb",
   "metadata": {},
   "source": [
    "### Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "10d6ea75-4b6f-42f5-8860-9767d238ad83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+--------+-------------+--------------+\n",
      "|Order ID|Order Date|Item Name|Quantity|Product Price|Total products|\n",
      "+--------+----------+---------+--------+-------------+--------------+\n",
      "+--------+----------+---------+--------+-------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r1_orders_df.filter(col(\"Order ID\").isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bb12d4f3-007f-4e19-be9d-e85d2a67bc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Restaurant 1 Orders missing values:\n",
      "+--------+----------+---------+--------+-------------+--------------+\n",
      "|Order ID|Order Date|Item Name|Quantity|Product Price|Total products|\n",
      "+--------+----------+---------+--------+-------------+--------------+\n",
      "|       0|         0|        0|       0|            0|             0|\n",
      "+--------+----------+---------+--------+-------------+--------------+\n",
      "\n",
      "\n",
      "Restaurant 2 Orders missing values:\n",
      "+--------+----------+---------+--------+-------------+--------------+\n",
      "|Order ID|Order Date|Item Name|Quantity|Product Price|Total products|\n",
      "+--------+----------+---------+--------+-------------+--------------+\n",
      "|       0|         0|        0|       0|            0|             0|\n",
      "+--------+----------+---------+--------+-------------+--------------+\n",
      "\n",
      "\n",
      "Restaurant 1 Products missing values:\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `Order ID` cannot be resolved. Did you mean one of the following? [`Item Name`, `Product Price`].;\n'Aggregate [sum(cast(isnull('Order ID) as int)) AS Order ID#1314, sum(cast(isnull('Order Date) as int)) AS Order Date#1316, sum(cast(isnull(Item Name#78) as int)) AS Item Name#1318L, sum(cast(isnull('Quantity) as int)) AS Quantity#1320, sum(cast(isnull(Product Price#79) as int)) AS Product Price#1322L, sum(cast(isnull('Total products) as int)) AS Total products#1324]\n+- Relation [Item Name#78,Product Price#79] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, df \u001b[38;5;129;01min\u001b[39;00m dfs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m missing values:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misNull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr1_orders_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:3223\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   3178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcols: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   3179\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   3180\u001b[0m \n\u001b[1;32m   3181\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3221\u001b[0m \u001b[38;5;124;03m    +-----+---+\u001b[39;00m\n\u001b[1;32m   3222\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3223\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jcols\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `Order ID` cannot be resolved. Did you mean one of the following? [`Item Name`, `Product Price`].;\n'Aggregate [sum(cast(isnull('Order ID) as int)) AS Order ID#1314, sum(cast(isnull('Order Date) as int)) AS Order Date#1316, sum(cast(isnull(Item Name#78) as int)) AS Item Name#1318L, sum(cast(isnull('Quantity) as int)) AS Quantity#1320, sum(cast(isnull(Product Price#79) as int)) AS Product Price#1322L, sum(cast(isnull('Total products) as int)) AS Total products#1324]\n+- Relation [Item Name#78,Product Price#79] csv\n"
     ]
    }
   ],
   "source": [
    "dfs = {\n",
    "    \"Restaurant 1 Orders\": r1_orders_df,\n",
    "    \"Restaurant 2 Orders\": r2_orders_df,\n",
    "    \"Restaurant 1 Products\": r1_prices_df,\n",
    "    \"Restaurant 2 Products\": r2_prices_df\n",
    "}\n",
    "\n",
    "\n",
    "for name, df in dfs.items():\n",
    "    print(f\"\\n{name} missing values:\")\n",
    "    df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in r1_orders_df.columns]).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50528d15-55cb-408e-b711-69bc931e2bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
